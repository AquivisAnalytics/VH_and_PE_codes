{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sklearn definitivo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7FhgOCYpjtS_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTTIGfzvN8mC"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import datetime\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from google.colab import files\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FhgOCYpjtS_"
      },
      "source": [
        "#Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sby4LM0k0IM"
      },
      "source": [
        "dd =  pd.read_csv(\"factors_2_numbers.csv\")\n",
        "#Delete empty columns\n",
        "dd = dd.drop(['mg_sacu_seguim','ttm_seguim___31','ttm_seguim___32','ara2_seguim___3','islgt2_seguim___4','naco_seguim___5'],1)\n",
        "dd = dd.iloc[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WRtkD67KiMc"
      },
      "source": [
        "#Select categorical variables\n",
        "categorical = ['sexe','data_visita_year','data_visita_month','data_visita_week','data_visita_day','procedencia','motiu_derivacio___1','motiu_derivacio___2','motiu_derivacio___3','motiu_derivacio___4','motiu_derivacio___5','motiu_derivacio___6','motiu_derivacio___7','motiu_derivacio___8','etiologia___1','etiologia___2','etiologia___3','etiologia___4','etiologia___5','etiologia___6','etiologia___7','etiologia___8','etiologia___9','etiologia___10','etiologia___11','etiologia___12','etiologia___13','antecedents___1','antecedents___2','antecedents___3','antecedents___4','antecedents___5','antecedents___6','antecedents___7','antecedents___8','antecedents___9','antecedents___10','antecedents___11','antecedents___12','antecedents___21','antecedents___13','antecedents___14','antecedents___15','antecedents___16','antecedents___17','antecedents___18','antecedents___20','neoplasia_estat','neoplasia_qt','tipus_iqprevia','insuf_mitral_seguim','ritme_base_seguim','trastorn_conduccio_t_v_1','marca','tto_ev_tipo___1','tto_ev_tipo___2','tto_ev_tipo___3','tto_ev_tipo___4','tto_ev_tipo___5','classe_funcional_seguim','ttm_seguim___1','ttm_seguim___2','ttm_seguim___3','ttm_seguim___4','ttm_seguim___5','ttm_seguim___6','ttm_seguim___7','ttm_seguim___8','ttm_seguim___9','ttm_seguim___10','ttm_seguim___11','ttm_seguim___12','ttm_seguim___13','ttm_seguim___14','ttm_seguim___15','ttm_seguim___16','ttm_seguim___17','ttm_seguim___18','ttm_seguim___19','ttm_seguim___20','ttm_seguim___21','ttm_seguim___22','ttm_seguim___23','ttm_seguim___24','ttm_seguim___25','ttm_seguim___26','ttm_seguim___27','ttm_seguim___28','ttm_seguim___29','ttm_seguim___30','ttm_seguim___33','diur_segui___1','diur_segui___2','diur_segui___3','mg_diur_segui','tiaz_seguim___1','tiaz_seguim___2','tiaz_seguim___3','mg_tiaz_seguim','antial_seguim___1','antial_seguim___2','antial_seguim___3','mg_anti_seguim','ieca_seguim___1','ieca_seguim___2','ieca_seguim___3','ieca_seguim___4','mg_ieca_seguim','ara2_seguim___1','ara2_seguim___2','ara2_seguim___4','mg_ara2_seguim','beta_seguim___1','beta_seguim___2','beta_seguim___3','beta_seguim___4','beta_seguim___5','mg_beta_seguim','islgt2_seguim___1','islgt2_seguim___2','islgt2_seguim___3','mg_islgt2_seguim','naco_seguim___1','naco_seguim___2','naco_seguim___3','naco_seguim___4','mg_naco_seguim','estacio_visita','IMC','mg_diur_segui']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxepCCBojzBA"
      },
      "source": [
        "One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnGSjk8Vjva4"
      },
      "source": [
        "catdf = pd.get_dummies(dd[categorical].astype(str))\n",
        "onehotdd = dd.copy()\n",
        "onehotdd.drop(categorical, axis=1, inplace=True)\n",
        "#One-hot encoding only on numerical variables\n",
        "onehotdd = pd.concat([catdf, onehotdd], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iQDebbxj0ju"
      },
      "source": [
        "Scaled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znFfKf-Dj1kf"
      },
      "source": [
        "#Scaling numeric variables\n",
        "numeric_cols = dd.drop(categorical, axis=1).columns\n",
        "y = dd.iloc[:,dd.shape[1]-4:dd.shape[1]]\n",
        "dd_scaled = dd.copy()\n",
        "dd_scaled[numeric_cols]=(dd_scaled[numeric_cols]-dd_scaled[numeric_cols].mean())/dd_scaled[numeric_cols].std()\n",
        "dd_scaled = dd_scaled.drop(y.columns, axis = 1)\n",
        "dd_scaled = pd.concat([dd_scaled, y], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAJZk-pIJWHx"
      },
      "source": [
        "###Final training data set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVOwXmRi_Pn7"
      },
      "source": [
        "dd_train = dd.sample(frac=0.7,random_state=123)\n",
        "dd_val = dd.drop(dd_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv8IT-lYQK5B"
      },
      "source": [
        "In order to compare the performance of the models with those trained in R with 3x3 CV, we use a 70% of the data to train the Sklearn models. We scale the data because in previous tests it has been seen that this preprocessing achieves the best performance for SVM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxRAnlsygDU3"
      },
      "source": [
        "dd_train_scaled = dd_scaled.sample(frac=0.7,random_state=123) \n",
        "dd_val = dd.drop(dd_train_scaled.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gx-N4HWjwXz"
      },
      "source": [
        "#Training the models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55JAhUf7J284"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "def model_function_completed(dd, model_name, balancing = \"none\", sampling =\"standard\",\n",
        "                             LDA_priors = None, LDA_shrinkage=None, LDA_solver='svd',\n",
        "                             QDA_priors = None, QDA_reg_param = -1,\n",
        "                             SVM_kernel = 'duh', SVM_C = -1, SVM_CW = None, SVM_Gamma = \"scale\", SVM_Degree=3, SVM_Coef0=0.0, SVM_shrinking = False):\n",
        "\n",
        "  oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "  undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "  \n",
        "  accuracy = [0,0,0,0]\n",
        "  sensitivity = [0,0,0,0]\n",
        "  specificity = [0,0,0,0]\n",
        "  score = [0,0,0,0]\n",
        "\n",
        "  #10 CV\n",
        "  for j in range(10):\n",
        "\n",
        "    n_cols = dd.shape[1]\n",
        "    y = dd.iloc[:,n_cols-4:n_cols]\n",
        "    \n",
        "    #SAMPLING METHOD\n",
        "    if (sampling == \"standard\"):\n",
        "      \n",
        "      train = dd.sample(frac=0.7,random_state=200+j) #random state is a seed value\n",
        "      test = dd.drop(train.index)\n",
        "      n_cols = dd.shape[1]\n",
        "      x_train = train.iloc[:,:n_cols-4]\n",
        "      y_train = train.iloc[:,n_cols-4:n_cols]\n",
        "      x_test = test.iloc[:,:n_cols-4]\n",
        "      y_test = test.iloc[:,n_cols-4:n_cols]\n",
        "      \n",
        "    \n",
        "    elif (sampling == \"balanced_resampling\"):\n",
        "      \n",
        "      n_cols = dd.shape[1]\n",
        "      x_train, x_test, y_train, y_test = train_test_split(dd.iloc[:,:n_cols-4],dd.iloc[:,n_cols-4:n_cols], test_size=0.3, random_state=123+j, stratify=y[['target_1', 'target_6', 'target_12']])\n",
        "\n",
        "    #for each target\n",
        "    for i in range(4):\n",
        "\n",
        "      #BALANCING METHOD\n",
        "      #oversample\n",
        "      if (balancing == 'oversample'):\n",
        "        x_train_balanced, y_train_balanced = oversample.fit_resample(x_train,\n",
        "        y_train.iloc[:,i])\n",
        "      #undersample\n",
        "      elif (balancing == 'undersample'):\n",
        "        x_train_balanced, y_train_balanced = undersample.fit_resample(x_train,\n",
        "        y_train.iloc[:,i])\n",
        "      #none\n",
        "      elif (balancing == 'none'):\n",
        "        x_train_balanced = x_train\n",
        "        y_train_balanced = y_train.iloc[:,i]\n",
        "\n",
        "      #MODEL NAME\n",
        "      if (model_name == \"LDA\"):\n",
        "        if (LDA_solver == 'svd'):\n",
        "          #shrinkage is not supported for svd solver\n",
        "          mod = LinearDiscriminantAnalysis(priors = LDA_priors, solver = LDA_solver)\n",
        "        else:\n",
        "          mod = LinearDiscriminantAnalysis(priors = LDA_priors, shrinkage = LDA_shrinkage, solver = LDA_solver)\n",
        "\n",
        "      elif (model_name == \"QDA\"):\n",
        "        mod = QuadraticDiscriminantAnalysis(priors = QDA_priors, reg_param = QDA_reg_param)\n",
        "\n",
        "      elif (model_name == \"SVM\"):\n",
        "        mod = SVC(kernel=SVM_kernel, max_iter = 200, C = SVM_C, class_weight = SVM_CW, gamma = SVM_Gamma, degree = SVM_Degree, coef0 = SVM_Coef0, shrinking = SVM_shrinking)\n",
        "      \n",
        "      mod.fit(x_train_balanced, y_train_balanced)\n",
        "      test_prediction = mod.predict(x_test)\n",
        "      cm = confusion_matrix(y_test.iloc[:,i], test_prediction)\n",
        "\n",
        "      sensitivity[i] +=  (cm[1,1]/(cm[1,1]+cm[1,0]))/10\n",
        "      specificity[i] +=  (cm[0,0]/(cm[0,0]+cm[0,1]))/10\n",
        "      accuracy[i] += mod.score(x_test, y_test.iloc[:,i])/10\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  for i in range (4):\n",
        "    score[i] = 0.6*sensitivity[i] + 0.4*specificity[i]\n",
        "    \"\"\"results[i][0] = accuracy[i]\n",
        "    results[i][1] = sensitivity[i]\n",
        "    results[i][2] = specificity\"\"\"\n",
        "    \n",
        "  results = [accuracy,sensitivity,specificity,score]\n",
        "  return results\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWlFCje2gz6a"
      },
      "source": [
        "##Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mV7NJxFhBNi"
      },
      "source": [
        "In this section, the models are trained by optimizing their hyperparameters through tests with loops. The most efficient hyperameters (based in score) and their corresponding results in score (60% sensitivity + 40% specificity), accuracy, sensitivity and specificity are saved for each target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3eeisZAsfoN"
      },
      "source": [
        "###LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12TEUlHTsuUO",
        "outputId": "c93f2eb5-cb80-411a-f235-b91c705c91e2"
      },
      "source": [
        "prints = True\n",
        "#First hyperparameter: balancing method\n",
        "for method in ['none', 'oversample', 'undersample']: #undersample has the best performance for LDA\n",
        "  if (prints): \n",
        "    print(\"With the following balancing method:\", method)\n",
        "\n",
        "  #Hyperparameter optimitzation:\n",
        "  #Best score for each target, best hyperparameters for each target, other performance measurements for each target\n",
        "  max = [[0,0,0,0],[0,0,0,0],[0,0,0,0]] \n",
        "  \n",
        "  #Hyperparameter values\n",
        "  solver = ['svd', 'lsqr', 'eigen']\n",
        "  shrinkage = ['auto']#, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9]\n",
        "  sampling = [\"balanced_resampling\", \"standard\"]\n",
        "\n",
        "  #Second hyperparameter: solver (solv)\n",
        "  for solv in solver:\n",
        "    #Third hyperparameter: shrinkage (s)\n",
        "    for s in shrinkage:\n",
        "      #Fourth hyperparameter: priors (p)\n",
        "      for p in range (1,20): \n",
        "        prior =  [0.05*p,1-p*0.05]\n",
        "        #Fifth hyperparameter: sampling method (sa)\n",
        "        for sa in sampling:\n",
        "          #Training the model with all hyperparameter combinations\n",
        "          results = model_function_completed(dd_train, \"LDA\", LDA_priors = prior, balancing = method, sampling = sa, LDA_shrinkage = s, LDA_solver = solv)\n",
        "          #Select the hyperparameters that maximize the performance of the model for each target\n",
        "          for j in range (4): \n",
        "            if (max[0][j] < results[3][j]): #Comparison based in score\n",
        "              max[0][j] = results[3][j] #Maximum score\n",
        "              max[1][j] = [solv, s, prior[0], sa] #Best solv, s, prior, sa based in score\n",
        "              max[2][j] = [results[0][j], results[1][j], results[2][j]] #Accuracy, sensitivy, specificity\n",
        "\n",
        "  print(max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With the following balancing method: none\n",
            "[[0.8380184331797234, 0.8093711551606289, 0.8064780763790664, 0.8080871072181844], [['lsqr', 'auto', 0.1, 'balanced_resampling'], ['lsqr', 'auto', 0.1, 'balanced_resampling'], ['lsqr', 'auto', 0.15000000000000002, 'balanced_resampling'], ['lsqr', 'auto', 0.15000000000000002, 'balanced_resampling']], [[0.8686098654708521, 0.8166666666666665, 0.8700460829493087], [0.7739910313901345, 0.8357142857142857, 0.7698564593301436], [0.7905829596412557, 0.8190476190476189, 0.7876237623762375], [0.7914798206278028, 0.8212121212121212, 0.7883995862272793]]]\n",
            "With the following balancing method: oversample\n",
            "[[0.765668202764977, 0.7389336978810663, 0.7749646393210747, 0.7848134984074099], [['lsqr', 'auto', 0.05, 'balanced_resampling'], ['lsqr', 'auto', 0.05, 'balanced_resampling'], ['lsqr', 'auto', 0.30000000000000004, 'balanced_resampling'], ['lsqr', 'auto', 0.45, 'balanced_resampling']], [[0.9313901345291481, 0.65, 0.9391705069124425], [0.8295964125560539, 0.6714285714285715, 0.8401913875598086], [0.8336322869955156, 0.7285714285714284, 0.8445544554455443], [0.863677130044843, 0.7222943722943722, 0.8785921875769664]]]\n",
            "With the following balancing method: undersample\n",
            "[[0.851152073732719, 0.7986124401913877, 0.8121056091063557, 0.8147718204656287], [['eigen', 'auto', 0.2, 'balanced_resampling'], ['lsqr', 'auto', 0.35000000000000003, 'balanced_resampling'], ['lsqr', 'auto', 0.25, 'standard'], ['lsqr', 'auto', 0.6000000000000001, 'balanced_resampling']], [[0.7811659192825112, 0.9, 0.7778801843317973], [0.7295964125560539, 0.8500000000000001, 0.7215311004784689], [0.742152466367713, 0.8677032502204127, 0.7287091474352699], [0.800896860986547, 0.8257575757575758, 0.798293187527708]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21Hhm1jZx3TN"
      },
      "source": [
        "###QDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqkKt7Wr_1uf",
        "outputId": "c059e03c-10ab-4422-c74e-4aa60529c1d4"
      },
      "source": [
        "prints = True\n",
        "#First hyperparameter: balancing method\n",
        "for method in ['undersample']: #'none', 'oversample', \n",
        "  if (prints): \n",
        "    print(\"With the following balancing method:\", method)\n",
        "\n",
        "  #Hyperparameter optimitzation:\n",
        "  #Best score for each target, best hyperparameters for each target, other performance measurements for each target\n",
        "  max = [[0,0,0,0],[0,0,0,0],[0,0,0,0]] \n",
        "  \n",
        "  #Hyperparameter values\n",
        "  data = ['original', 'scaled']\n",
        "  sampling = [\"balanced_resampling\", \"standard\"]\n",
        "\n",
        "  #Second hyperparameter: data (d)\n",
        "  for d in data:\n",
        "    #Third hyperparameter: regularization parameter (rp)\n",
        "    for rp in range (0,20): \n",
        "      reg_param = 0.05*rp\n",
        "      #Fourth hyperparameter: priors (p)\n",
        "      for p in range (1,20): \n",
        "        prior =  [0.05*p,1-p*0.05]\n",
        "        #Fifth hyperparameter: sampling method (sa)\n",
        "        for sa in sampling:\n",
        "          #Training the model with all hyperparameter combinations\n",
        "          if (d == 'original'):\n",
        "            results = model_function_completed(dd_train, \"QDA\", balancing = method, sampling = sa, QDA_priors = prior, QDA_reg_param = reg_param)\n",
        "          elif (d == 'scaled'):\n",
        "            results = model_function_completed(dd_train_scaled, \"QDA\", balancing = method, sampling = sa, QDA_priors = prior, QDA_reg_param = reg_param)\n",
        "          #Select the hyperparameters that maximize the performance of the model for each target\n",
        "          for j in range (4): \n",
        "            if (max[0][j] < results[3][j]): #Comparison based in score\n",
        "              max[0][j] = results[3][j] #Maximum score\n",
        "              max[1][j] = [d, reg_param, prior[0], sa] #Best d, rp, prior, sa based in score\n",
        "              max[2][j] = [results[0][j], results[1][j], results[2][j]] #Accuracy, sensitivy, specificity\n",
        "\n",
        "  print(max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With the following balancing method: undersample\n",
            "[[0.6861751152073732, 0.6800546821599454, 0.7278925035360679, 0.7308924009936049], [['original', 0.6000000000000001, 0.15000000000000002, 'balanced_resampling'], ['original', 0.35000000000000003, 0.1, 'balanced_resampling'], ['original', 0.8500000000000001, 0.05, 'balanced_resampling'], ['original', 0.35000000000000003, 0.30000000000000004, 'standard']], [[0.6663677130044843, 0.7, 0.6654377880184331], [0.6340807174887892, 0.7142857142857144, 0.6287081339712918], [0.7511210762331839, 0.7095238095238096, 0.7554455445544553], [0.7744394618834082, 0.6950762327312078, 0.7846166533872005]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6gXMC_Vj4Lz"
      },
      "source": [
        "###SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJW3TFXRKdB"
      },
      "source": [
        "####LINEAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmVbUv1kRH85",
        "outputId": "95d4e9b0-e3ce-48d2-ce12-ddb1c4f1a28e"
      },
      "source": [
        "prints = True\n",
        "kernel = 'linear'\n",
        "#First hyperparameter: balancing method\n",
        "for method in ['none', 'oversample', 'undersample']: #undersampling has the best performance for SVM\n",
        "  if (prints): \n",
        "    print(\"With the following balancing method:\", method)\n",
        "\n",
        "  #Hyperparameter optimitzation:\n",
        "  #Best score for each target, best hyperparameters for each target, other performance measurements for each target\n",
        "  max = [[0,0,0,0],[0,0,0,0],[0,0,0,0]] \n",
        "  \n",
        "  #Hyperparameter values\n",
        "  c_values = [1, 5, 10, 20, 50, 100]\n",
        "  cw_values = [\"balanced\", None]\n",
        "  sampling = [\"balanced_resampling\", \"standard\"]\n",
        "  shrinking = [True, False]\n",
        "\n",
        "  #Second hyperparameter: cost (c)\n",
        "  for c in c_values: \n",
        "    #Third hyperparameter: class weight (cw)\n",
        "    for cw in cw_values:\n",
        "      #Fourth hyperparameter: shrinking (s)\n",
        "      for s in shrinking:\n",
        "        #Fifth hyperparameter: sampling method (sa)\n",
        "        for sa in sampling:\n",
        "          #Training the model with all hyperparameter combinations\n",
        "          results = model_function_completed(dd_train_scaled, \"SVM\", SVM_kernel = kernel, balancing = method, sampling = sa, SVM_C = c, SVM_CW = cw, SVM_shrinking = s)\n",
        "          #Select the hyperparameters that maximize the performance of the model for each target\n",
        "          for j in range (4): \n",
        "            if (max[0][j] < results[3][j]): #Comparison based in score\n",
        "              max[0][j] = results[3][j] #Maximum score\n",
        "              max[1][j] = [c,cw,s,sa] #Best c, cw, s, s based in score\n",
        "              max[2][j] = [results[0][j], results[1][j], results[2][j]] #Accuracy, sensitivy, specificity\n",
        "  \n",
        "  print(max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With the following balancing method: none\n",
            "[[0.6069604796932183, 0.6040855992413542, 0.6731036309913772, 0.6964365327790774], [[1, 'balanced', True, 'standard'], [1, 'balanced', True, 'standard'], [1, 'balanced', True, 'standard'], [1, 'balanced', True, 'balanced_resampling']], [[0.9591928251121076, 0.36000000000000004, 0.9774011992330457], [0.8860986547085202, 0.3906848706848707, 0.9241866920760794], [0.875336322869955, 0.5099968300197132, 0.917763832448873], [0.8834080717488789, 0.5482683982683982, 0.9186887345450961]]]\n",
            "With the following balancing method: oversample\n",
            "[[0.6069604796932183, 0.6040855992413542, 0.6731036309913772, 0.6964365327790774], [[1, 'balanced', True, 'standard'], [1, 'balanced', True, 'standard'], [1, 'balanced', True, 'standard'], [1, 'balanced', True, 'balanced_resampling']], [[0.9591928251121076, 0.36000000000000004, 0.9774011992330457], [0.8860986547085202, 0.3906848706848707, 0.9241866920760794], [0.875336322869955, 0.5099968300197132, 0.917763832448873], [0.8834080717488789, 0.5482683982683982, 0.9186887345450961]]]\n",
            "With the following balancing method: undersample\n",
            "[[0.8293548387096773, 0.7639371155160628, 0.7875247524752476, 0.786206238960783], [[1, None, True, 'balanced_resampling'], [20, None, False, 'balanced_resampling'], [100, None, True, 'balanced_resampling'], [100, None, True, 'balanced_resampling']], [[0.7520179372197309, 0.8833333333333332, 0.7483870967741935], [0.6771300448430493, 0.8285714285714285, 0.6669856459330143], [0.7295964125560538, 0.8333333333333334, 0.7188118811881187], [0.7417040358744396, 0.8214285714285714, 0.7333727402591005]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isS6XaLnQTgF"
      },
      "source": [
        "####POLY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "fvZxmngdok3n",
        "outputId": "0926225d-4f34-4ba6-9c6e-fc1be88cdcf3"
      },
      "source": [
        "prints = True\n",
        "kernel = 'poly'\n",
        "#First hyperparameter: balancing method\n",
        "for method in ['none', 'oversample', 'undersample']: #undersampling has the best performance for SVM\n",
        "  if (prints): \n",
        "    print(\"With the following balancing method:\", method)\n",
        "\n",
        "  #Hyperparameter optimitzation:\n",
        "  #Best score for each target, best hyperparameters for each target, other performance measurements for each target\n",
        "  max = [[0,0,0,0],[0,0,0,0],[0,0,0,0]] \n",
        "  \n",
        "  #Hyperparameter values\n",
        "  degrees = [2, 3, 4, 6, 8, 10]\n",
        "  coef = [0.0, 0.5,1.0, 5.0, 10.0, 20.0, 50.0, 100.0]\n",
        "  c_values = [1, 5, 10, 20, 50, 100]\n",
        "  cw_values = [\"balanced\", None]\n",
        "  shrinking = [True, False]\n",
        "  \n",
        "  #Second hyperparameter: cost (c)\n",
        "  for c in c_values: \n",
        "    #Third hyperparameter: class weight (cw)\n",
        "    for cw in cw_values:\n",
        "      #Fourth hyperparameter: shrinking (s)\n",
        "      for s in shrinking:\n",
        "        #Fifth hyperparameter: degree (d)\n",
        "        for d in degrees:\n",
        "          #Sixth hyperparameter: coeficient (co)\n",
        "          for co in coef:\n",
        "            #Training the model with all hyperparameter combinations\n",
        "            results = model_function_completed(dd_train_scaled, \"SVM\", SVM_kernel=kernel, balancing = method, sampling = \"balanced_resampling\", SVM_C = c, SVM_CW = cw, SVM_shrinking = s, SVM_Coef0= co, SVM_Degree=d)\n",
        "            #Select the hyperparameters that maximize the performance of the model for each target\n",
        "            for j in range (4): \n",
        "              if (max[0][j] < results[3][j]): #Comparison based in score\n",
        "                max[0][j] = results[3][j] #Maximum score\n",
        "                max[1][j] = [c,cw,s,d,co] #Best c, cw, s, d, co based in score\n",
        "                max[2][j] = [results[0][j], results[1][j], results[2][j]] #Accuracy, sensitivy, specificity\n",
        "  \n",
        "  print(max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With the following balancing method: none\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e62397d60fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mco\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m#Training the model with all hyperparameter combinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_function_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalancing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"balanced_resampling\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_CW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_shrinking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_Coef0\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM_Degree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m#Select the hyperparameters that maximize the performance of the model for each target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-8f8fdf85f4d4>\u001b[0m in \u001b[0;36mmodel_function_completed\u001b[0;34m(dd, model_name, balancing, sampling, LDA_priors, LDA_shrinkage, LDA_solver, QDA_priors, QDA_reg_param, SVM_kernel, SVM_C, SVM_CW, SVM_Gamma, SVM_Degree, SVM_Coef0, SVM_shrinking)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_CW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_Gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_Degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_Coef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_shrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_balanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGH5s8qCCDiD"
      },
      "source": [
        "####RBF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp4tFVk6CI6o",
        "outputId": "abf9058c-65bd-46ba-c136-49a97df2bbe0"
      },
      "source": [
        "prints = True\n",
        "kernel = 'sigmoid'\n",
        "#First hyperparameter: balancing method\n",
        "for method in ['none', 'oversample', 'undersample']: #undersampling has the best performance for SVM\n",
        "  if (prints): \n",
        "    print(\"With the following balancing method:\", method)\n",
        "\n",
        "  #Hyperparameter optimitzation:\n",
        "  #Best score for each target, best hyperparameters for each target, other performance measurements for each target\n",
        "  max = [[0,0,0,0],[0,0,0,0],[0,0,0,0]] \n",
        "  \n",
        "  #Hyperparameter values\n",
        "  gamma =  ['scale', 0.5, 1, 2, 5, 7, 10]\n",
        "  c_values = [1, 3, 5, 10, 20, 50, 75, 100]\n",
        "  cw_values = [\"balanced\", None]\n",
        "  shrinking = [True, False]\n",
        "  \n",
        "  #Second hyperparameter: cost (c)\n",
        "  for c in c_values: \n",
        "    #Third hyperparameter: class weight (cw)\n",
        "    for cw in cw_values:\n",
        "      #Fourth hyperparameter: shrinking (s)\n",
        "      for s in shrinking:\n",
        "        #Fifth hyperparameter: gamma (g)\n",
        "        for g in gamma:\n",
        "          #Training the model with all hyperparameter combinations\n",
        "          results = model_function_completed(dd_train_scaled, \"SVM\", SVM_kernel=kernel, balancing = method, sampling = \"balanced_resampling\", SVM_C = c, SVM_CW = cw, SVM_shrinking = s, SVM_Gamma = g)\n",
        "          #Select the hyperparameters that maximize the performance of the model for each target\n",
        "          for j in range (4): \n",
        "            if (max[0][j] < results[3][j]): #Comparison based in score\n",
        "              max[0][j] = results[3][j] #Maximum score\n",
        "              max[1][j] = [c,cw,s,g] #Best c, cw, s, g based in score\n",
        "              max[2][j] = [results[0][j], results[1][j], results[2][j]] #Accuracy, sensitivy, specificity\n",
        "\n",
        "  print(max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With the following balancing method: none\n",
            "[[0.5999999999999999, 0.5999999999999999, 0.5999999999999999, 0.5999999999999999], [[1, 'balanced', True, 'scale'], [1, 'balanced', True, 'scale'], [1, 'balanced', True, 'scale'], [1, 'balanced', True, 'scale']], [[0.026905829596412557, 0.9999999999999999, 0.0], [0.06278026905829596, 0.9999999999999999, 0.0], [0.09417040358744395, 0.9999999999999999, 0.0], [0.09506726457399103, 0.9999999999999999, 0.0]]]\n",
            "With the following balancing method: oversample\n",
            "[[0.818294930875576, 0.7569924812030076, 0.7492786421499292, 0.7568837694003943], [[3, None, False, 'scale'], [5, 'balanced', True, 'scale'], [50, 'balanced', False, 'scale'], [50, 'balanced', False, 'scale']], [[0.6295964125560538, 0.9500000000000001, 0.62073732718894], [0.5457399103139013, 0.9142857142857144, 0.5210526315789473], [0.5466367713004484, 0.9095238095238096, 0.5089108910891088], [0.5511210762331837, 0.9199134199134199, 0.5123392936308556]]]\n",
            "With the following balancing method: undersample\n",
            "[[0.6636866359447006, 0.5999999999999999, 0.6277510608203678, 0.6246716142829636], [[50, 'balanced', True, 'scale'], [1, 'balanced', True, 0.5], [10, None, True, 'scale'], [50, 'balanced', True, 'scale']], [[0.6116591928251122, 0.7000000000000001, 0.6092165898617512], [0.06278026905829596, 0.9999999999999999, 0.0], [0.6327354260089687, 0.6238095238095239, 0.6336633663366336], [0.590134529147982, 0.6519480519480519, 0.5837569577853309]]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}